@doc raw"""
SAE(weight,bias,σ)

Canonical sparse autoencoder architecture adapted from [1]. Weights are symmetric. For nonsymmetric weights, define separate encoder and decoder layers using the Autoencoder class.

[1] Bricken, et al., "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning", Transformer Circuits Thread, 2023.
"""
struct SAE <: SparseEncoder
    weight::AbstractArray
    bias::AbstractArray
    σ::Function
end
# the magic line that makes everything "just work"
@functor SAE 
